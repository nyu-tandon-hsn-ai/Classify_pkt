{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = np.asarray(df[name], dtype = np.float).mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = np.asarray(df[name], dtype = np.float).std()\n",
    "\n",
    "    df[name] = (np.asarray(df[name], dtype = np.float) - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read df_ 752285 rows.\n",
      "Read df_test 322409 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "df_ = pd.read_csv(\"./train_70%.csv\")\n",
    "df_test = pd.read_csv(\"./test_30%.csv\")\n",
    "print(\"Read df_ {} rows.\".format(len(df_)))\n",
    "print(\"Read df_test {} rows.\".format(len(df_test)))\n",
    "#print(\"Read {} rows.\".format(len(df1)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df_ = df_.drop(df_.columns[0], axis=1)\n",
    "df_test = df_test.drop(df_test.columns[0], axis=1)\n",
    "\n",
    "df_.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "df_test.dropna(inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remote_ip2num</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>is_udp</th>\n",
       "      <th>pkt_len</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3419258414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>bili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1747765669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>skype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3225463870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>LoL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1747765669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>skype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3225463870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>795</td>\n",
       "      <td>LoL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   remote_ip2num  is_tcp  is_udp  pkt_len outcome\n",
       "0     3419258414       1       0     1300    bili\n",
       "1     1747765669       0       1      906   skype\n",
       "2     3225463870       0       1      147     LoL\n",
       "3     1747765669       0       1      320   skype\n",
       "4     3225463870       0       1      795     LoL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remote_ip2num</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>is_udp</th>\n",
       "      <th>pkt_len</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3419258414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>bili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1747765669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>skype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3225463870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>LoL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1747765669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>skype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3225463870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>795</td>\n",
       "      <td>LoL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   remote_ip2num  is_tcp  is_udp  pkt_len outcome\n",
       "0     3419258414       1       0     1300    bili\n",
       "1     1747765669       0       1      906   skype\n",
       "2     3225463870       0       1      147     LoL\n",
       "3     1747765669       0       1      320   skype\n",
       "4     3225463870       0       1      795     LoL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # Now encode the feature vector\n",
    "\n",
    "# # # encode_text_dummy(df, 'protocol_type')\n",
    "# # encode_numeric_zscore(df, 'forw_byte')\n",
    "# # encode_numeric_zscore(df, 'back_byte')\n",
    "# # encode_numeric_zscore(df, 'tot_byte')\n",
    "\n",
    "# encode_numeric_zscore(df_, ' Flow Duration')\n",
    "# encode_numeric_zscore(df_, ' Total Fwd Packets')\n",
    "# encode_numeric_zscore(df_, ' Total Backward Packets')\n",
    "# encode_numeric_zscore(df_, 'Total Length of Fwd Packets')\n",
    "# encode_numeric_zscore(df_, ' Total Length of Bwd Packets')\n",
    "# encode_numeric_zscore(df_, ' Fwd Packet Length Max')\n",
    "# encode_numeric_zscore(df_, ' Fwd Packet Length Min')\n",
    "# encode_numeric_zscore(df_, ' Fwd Packet Length Mean')\n",
    "# encode_numeric_zscore(df_, ' Fwd Packet Length Std')\n",
    "# encode_numeric_zscore(df_, 'Bwd Packet Length Max')\n",
    "# encode_numeric_zscore(df_, ' Bwd Packet Length Min')\n",
    "# encode_numeric_zscore(df_, ' Bwd Packet Length Mean')\n",
    "# encode_numeric_zscore(df_, ' Bwd Packet Length Std')\n",
    "# encode_numeric_zscore(df_, ' Min Packet Length')\n",
    "# encode_numeric_zscore(df_, ' Max Packet Length')\n",
    "# encode_numeric_zscore(df_, ' Packet Length Mean')\n",
    "# encode_numeric_zscore(df_, ' Packet Length Std')\n",
    "# encode_numeric_zscore(df_, 'total pkt count')\n",
    "# encode_numeric_zscore(df_, 'total byte count')\n",
    "\n",
    "# encode_numeric_zscore(df_test, ' Flow Duration')\n",
    "# encode_numeric_zscore(df_test, ' Total Fwd Packets')\n",
    "# encode_numeric_zscore(df_test, ' Total Backward Packets')\n",
    "# encode_numeric_zscore(df_test, 'Total Length of Fwd Packets')\n",
    "# encode_numeric_zscore(df_test, ' Total Length of Bwd Packets')\n",
    "# encode_numeric_zscore(df_test, ' Fwd Packet Length Max')\n",
    "# encode_numeric_zscore(df_test, ' Fwd Packet Length Min')\n",
    "# encode_numeric_zscore(df_test, ' Fwd Packet Length Mean')\n",
    "# encode_numeric_zscore(df_test, ' Fwd Packet Length Std')\n",
    "# encode_numeric_zscore(df_test, 'Bwd Packet Length Max')\n",
    "# encode_numeric_zscore(df_test, ' Bwd Packet Length Min')\n",
    "# encode_numeric_zscore(df_test, ' Bwd Packet Length Mean')\n",
    "# encode_numeric_zscore(df_test, ' Bwd Packet Length Std')\n",
    "# encode_numeric_zscore(df_test, ' Min Packet Length')\n",
    "# encode_numeric_zscore(df_test, ' Max Packet Length')\n",
    "# encode_numeric_zscore(df_test, ' Packet Length Mean')\n",
    "# encode_numeric_zscore(df_test, ' Packet Length Std')\n",
    "# encode_numeric_zscore(df_test, 'total pkt count')\n",
    "# encode_numeric_zscore(df_test, 'total byte count')\n",
    "\n",
    "# encode_text_index(df_, ' Label')\n",
    "# encode_text_index(df_test, ' Label')\n",
    "# # num_classes = len(outcomes)\n",
    "\n",
    "# # # display 5 rows\n",
    "\n",
    "# # df.dropna(inplace=True,axis=1)\n",
    "# # df[0:5]\n",
    "# # # This is the numeric feature vector, as it goes to the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LoL', 'bili', 'download', 'netease', 'skype', 'tencent', 'youtube'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_numeric_zscore(df_, 'remote_ip2num')\n",
    "# encode_numeric_zscore(df_, 'is_tcp')\n",
    "# encode_numeric_zscore(df_, 'is_udp')\n",
    "encode_numeric_zscore(df_, 'pkt_len')\n",
    "encode_text_index(df_, 'outcome')\n",
    "encode_numeric_zscore(df_test, 'remote_ip2num')\n",
    "encode_numeric_zscore(df_test, 'pkt_len')\n",
    "encode_text_index(df_test, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = to_xy(df_, 'outcome')\n",
    "x_test, y_test = to_xy(df_test, 'outcome')\n",
    "# x, y = to_xy(df_, ' Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remote_ip2num</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>is_udp</th>\n",
       "      <th>pkt_len</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.587349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.415156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.275280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.947256</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.415156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   remote_ip2num  is_tcp  is_udp   pkt_len  outcome\n",
       "0       1.587349       1       0  0.910912        1\n",
       "1       0.102173       0       1  0.163852        4\n",
       "2       1.415156       0       1 -1.275280        0\n",
       "3       0.102173       0       1 -0.947256        4\n",
       "4       1.415156       0       1 -0.046614        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.14037454,  1.        ,  0.        ,  0.88518053],\n",
       "       [ 0.10253431,  0.        ,  1.        , -0.26666588],\n",
       "       [ 0.10253431,  0.        ,  1.        , -0.23061138],\n",
       "       ..., \n",
       "       [-1.18292356,  1.        ,  0.        ,  0.88518053],\n",
       "       [-1.18292356,  1.        ,  0.        ,  0.88518053],\n",
       "       [ 1.14037454,  1.        ,  0.        ,  0.88518053]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create neural net\n",
    "model = Sequential()\n",
    "\n",
    "# Used relu for activation function\n",
    "# model.add(Dense(4, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(8, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(4, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(3, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(y_train.shape[1],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 110\n",
      "Trainable params: 110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 752285 samples, validate on 322409 samples\n",
      "Epoch 1/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.3292 - acc: 0.9008 - val_loss: 0.1451 - val_acc: 0.9619\n",
      "Epoch 2/50\n",
      "752285/752285 [==============================] - 30s - loss: 0.1360 - acc: 0.9631 - val_loss: 0.1319 - val_acc: 0.9791\n",
      "Epoch 3/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.1271 - acc: 0.9647 - val_loss: 0.1250 - val_acc: 0.9799\n",
      "Epoch 4/50\n",
      "752285/752285 [==============================] - 24s - loss: 0.1226 - acc: 0.9667 - val_loss: 0.1177 - val_acc: 0.9807\n",
      "Epoch 5/50\n",
      "752285/752285 [==============================] - 24s - loss: 0.1107 - acc: 0.9707 - val_loss: 0.1087 - val_acc: 0.9670\n",
      "Epoch 6/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.1061 - acc: 0.9745 - val_loss: 0.1045 - val_acc: 0.9830\n",
      "Epoch 7/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.1031 - acc: 0.9778 - val_loss: 0.1022 - val_acc: 0.9833\n",
      "Epoch 8/50\n",
      "752285/752285 [==============================] - 24s - loss: 0.1005 - acc: 0.9805 - val_loss: 0.1006 - val_acc: 0.9829\n",
      "Epoch 9/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0982 - acc: 0.9827 - val_loss: 0.0976 - val_acc: 0.9830\n",
      "Epoch 10/50\n",
      "752285/752285 [==============================] - 29s - loss: 0.0961 - acc: 0.9836 - val_loss: 0.0953 - val_acc: 0.9838\n",
      "Epoch 11/50\n",
      "752285/752285 [==============================] - 28s - loss: 0.0944 - acc: 0.9840 - val_loss: 0.0936 - val_acc: 0.9839\n",
      "Epoch 12/50\n",
      "752285/752285 [==============================] - 27s - loss: 0.0928 - acc: 0.9842 - val_loss: 0.0933 - val_acc: 0.9838\n",
      "Epoch 13/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0913 - acc: 0.9842 - val_loss: 0.0910 - val_acc: 0.9839\n",
      "Epoch 14/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0893 - acc: 0.9842 - val_loss: 0.0903 - val_acc: 0.9839\n",
      "Epoch 15/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0879 - acc: 0.9843 - val_loss: 0.0875 - val_acc: 0.9840\n",
      "Epoch 16/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0870 - acc: 0.9843 - val_loss: 0.0862 - val_acc: 0.9840\n",
      "Epoch 17/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0861 - acc: 0.9843 - val_loss: 0.0892 - val_acc: 0.9840\n",
      "Epoch 18/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0853 - acc: 0.9843 - val_loss: 0.0867 - val_acc: 0.9840\n",
      "Epoch 19/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0838 - acc: 0.9843 - val_loss: 0.0835 - val_acc: 0.9839\n",
      "Epoch 20/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0823 - acc: 0.9843 - val_loss: 0.0815 - val_acc: 0.9840\n",
      "Epoch 21/50\n",
      "752285/752285 [==============================] - 24s - loss: 0.0808 - acc: 0.9843 - val_loss: 0.0806 - val_acc: 0.9840\n",
      "Epoch 22/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0799 - acc: 0.9844 - val_loss: 0.0797 - val_acc: 0.9840\n",
      "Epoch 23/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0792 - acc: 0.9849 - val_loss: 0.0787 - val_acc: 0.9850\n",
      "Epoch 24/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0787 - acc: 0.9852 - val_loss: 0.0797 - val_acc: 0.9850\n",
      "Epoch 25/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0782 - acc: 0.9853 - val_loss: 0.0782 - val_acc: 0.9850\n",
      "Epoch 26/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0777 - acc: 0.9853 - val_loss: 0.0773 - val_acc: 0.9850\n",
      "Epoch 27/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0774 - acc: 0.9853 - val_loss: 0.0772 - val_acc: 0.9850\n",
      "Epoch 28/50\n",
      "752285/752285 [==============================] - 25s - loss: 0.0771 - acc: 0.9853 - val_loss: 0.0768 - val_acc: 0.9850\n",
      "Epoch 29/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0769 - acc: 0.9853 - val_loss: 0.0773 - val_acc: 0.9850\n",
      "Epoch 30/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0767 - acc: 0.9853 - val_loss: 0.0769 - val_acc: 0.9850\n",
      "Epoch 31/50\n",
      "752285/752285 [==============================] - 24s - loss: 0.0766 - acc: 0.9853 - val_loss: 0.0763 - val_acc: 0.9850\n",
      "Epoch 32/50\n",
      "752285/752285 [==============================] - 26s - loss: 0.0764 - acc: 0.9853 - val_loss: 0.0772 - val_acc: 0.9850\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1125f3358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "batch_size = 100\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,batch_size = batch_size, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.9850407401778486\n"
     ]
    }
   ],
   "source": [
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 4 2 5 2 2 6 4 4 2 4 1 0 1 5 4 4 2 4 4 4 2 4 1 2 4 2 4 2 2 4 2 6 2 2 6\n",
      " 2 6 4 5 0 2 5 2 2 4 0 5 2 2 2 1 2 1 2 2 4 2 5 5 2 0 2 2 4 5 4 0 4 4 6 2 0\n",
      " 4 5 2 6 4 2 1 4 4 5 2 2 6 4 0 2 5 4 2 4 4 4 4 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_eval[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 4 2 5 2 2 6 4 4 2 4 1 0 1 5 4 4 2 4 4 4 2 4 1 2 4 2 4 2 2 4 2 6 2 2 6\n",
      " 2 6 4 5 0 2 5 2 2 4 0 5 2 2 2 1 2 1 2 2 4 2 5 5 2 0 2 2 4 5 4 0 4 4 6 2 0\n",
      " 4 5 2 6 4 2 1 4 4 5 2 2 6 4 0 2 5 4 2 4 4 4 4 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iff = np.ones(272618, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iff = 3*iff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0.0836  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.0882  0.0002  0.      0.      0.0031  0.0003]\n",
      " [ 0.      0.      0.3265  0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.0003  0.      0.      0.0027  0.    ]\n",
      " [ 0.      0.0001  0.0009  0.      0.3394  0.0026  0.0005]\n",
      " [ 0.      0.0004  0.0003  0.      0.0001  0.0889  0.0005]\n",
      " [ 0.      0.0001  0.0011  0.      0.      0.0015  0.0585]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Cm = confusion_matrix(y_eval,pred)\n",
    "C = np.sum(Cm)\n",
    "Cm = Cm/C\n",
    "print('Confusion Matrix:')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# print('DDos precision & recall & f1_score & support:')\n",
    "# typ = [ \"precision\", \"recall\", \"f1_score\", \"support\"]\n",
    "# ddos_prfs = precision_recall_fscore_support(y_eval, pred)\n",
    "# ddos_list = [x for x,_ in ddos_prfs]\n",
    "# for f, b in zip(typ, ddos_list):\n",
    "#     print( f, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal precision & recall & f1_score & support:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_recall_fscore_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c986f821ab2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Normal precision & recall & f1_score & support:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"support\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mddos_prfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mddos_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mddos_prfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddos_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_recall_fscore_support' is not defined"
     ]
    }
   ],
   "source": [
    "print('Normal precision & recall & f1_score & support:')\n",
    "typ = [ \"precision\", \"recall\", \"f1_score\", \"support\"]\n",
    "ddos_prfs = precision_recall_fscore_support(y_eval, pred)\n",
    "ddos_list = [_ for x,_ in ddos_prfs]\n",
    "for f, b in zip(typ, ddos_list):\n",
    "    print( f, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valAcc = history_cb.val_acc\n",
    "valLoss = history_cb.val_loss\n",
    "epoch_it = np.arange(1,16)\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_it, valAcc)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.tight_layout()\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_it, valLoss)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ls = history_cb.losses\n",
    "Acc = history_cb.accs\n",
    "ntr = np.shape(x_train)[0]\n",
    "epochNum = []\n",
    "for i in range(5040):\n",
    "    epochNum.append(i*100/ntr)\n",
    "\n",
    "plt.subplot(122)\n",
    "matplotlib.pyplot.semilogy(epochNum, Ls)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.subplot(121)\n",
    "matplotlib.pyplot.semilogy(epochNum, Acc)\n",
    "# plt.plot(epochNum, Acc)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.tight_layout()\n",
    "# plt.axis([0.3,3,0.96,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.pyplot.semilogy(epochNum, Acc)\n",
    "# plt.plot(epochNum, Acc)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.tight_layout()\n",
    "# plt.axis([0.3,3,0.96,1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# model.save('model_trained_nosampled_sampling@100%.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# # returns a compiled model\n",
    "# # identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hist = model.fit(x, y, validation_split=0.2)\n",
    "# print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.shape(hist.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model2 = load_model('model_trained_sampling@100%.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Measure accuracy\n",
    "# pred = model2.predict(x_test)\n",
    "# pred = np.argmax(pred,axis=1)\n",
    "# y_eval = np.argmax(y_test,axis=1)\n",
    "# score = metrics.accuracy_score(y_eval, pred)\n",
    "# print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
